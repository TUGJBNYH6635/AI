{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7Cifar10_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4pHBLtLY6oM",
        "colab_type": "code",
        "outputId": "8a456840-f04a-4a77-a80e-7771bad04282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train_), (x_test, y_test_) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255\n",
        "x_test = x_test.astype('float32') / 255\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "y_train = to_categorical(y_train_)\n",
        "y_test = to_categorical(y_test_)\n",
        "\n",
        "\"\"\"## Model Definition(模型定義\"\"\"\n",
        "\n",
        "from keras.models import Sequential\n",
        "model = Sequential()\n",
        "\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "\n",
        "model.add(Conv2D(filters=32, \n",
        "                kernel_size=(3, 3),\n",
        "                activation='relu',\n",
        "                input_shape=(32, 32, 3)))\n",
        "\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Conv2D(filters=64,\n",
        "                kernel_size=(3, 3),\n",
        "                activation='relu'))\n",
        "model.add(MaxPool2D())\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\"\"\"## Fitting\"\"\"\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=50, epochs=15, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(history_dict['acc']) + 1)\n",
        "\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.2211 - accuracy: 0.9346\n",
            "Epoch 2/5\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0977 - accuracy: 0.9709\n",
            "Epoch 3/5\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0689 - accuracy: 0.9779\n",
            "Epoch 4/5\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0524 - accuracy: 0.9829\n",
            "Epoch 5/5\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0421 - accuracy: 0.9860\n",
            "10000/10000 [==============================] - 0s 49us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.062029453077045035, 0.9815999865531921]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    }
  ]
}